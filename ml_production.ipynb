{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nbstripout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data eda/visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "#data modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#for github\n",
    "import nbstripout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"willianoliveiragibin/customer-churn\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "#resources:\n",
    "# https://www.datacamp.com/tutorial/understanding-logistic-regression-python\n",
    "# https://www.datacamp.com/tutorial/understanding-logistic-regression-python\n",
    "# https://www.datacamp.com/tutorial/random-forests-classifier-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Customer Churn new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below indicates that we do not have customers with multiple rows. Each customer is unique to its own singular row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.CustomerId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.RowNumber.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical narrative:\n",
    "\n",
    "Looking across our various quantitative columns, it appears to me that we have a evan spread of information. Starting with credit score, we see that our lowest value is 350 and highest is 850. This means the data properly represents a good spread of financially healthy individuals. Our age gap is great as we may be able to mix in Knearest Neighbors which are classification models. The tenure range is only 0 to 10 which may need to researched more. A gap of 10 days vs 10 years vastly changes the way we would think about the predictions. The balance represents the amount of money in the customers bank account, which again, we seem to have a healthy gap. Lastly, our estimated salary which I hypothesize to be our leading prediction indicator has an interesting minimum value of 11. I assume this is an error as making 11$ a year is not feasible, however the 25%, 50%, and 75% values seem to be in line with a typical yearly salary.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independant Variables (x values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data[['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']]\n",
    "data_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data_x, markers='o', diag_kind='hist', plot_kws={'color': 'red'}, diag_kws={'color': 'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further analysis needed**\n",
    "\n",
    "After reviewing the pairplt, we do not see any clear linear relationships, howeever we also do not see any drastic outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#note to self:\n",
    "\n",
    "May need to do more EDA on this dataset. Do a couple of graphs such as a heatmap, or grouping our salary, balance or age data.\n",
    "\n",
    "Idea: graph the salary and balance by age to see if there is a relationship.\n",
    "\n",
    "    Graph the amount of people by age and gender and geography to see if there is a relationship or trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking our different options (for automation we can code to have it find all the options and assign a number if needed)\n",
    "data['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Geography'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for modeling we usually only want to use numeric, meaning our string type values will have to be mapped to numeric (example: Male 0, Female 1)\n",
    "\n",
    "data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})\n",
    "data['Geography'] = data['Geography'].map({'France': 0, 'Spain': 1, 'Germany': 2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of customers who exited and didn't \n",
    "\n",
    "exited_percentage = data['Exited'].value_counts(normalize=True)\n",
    "print(exited_percentage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can keep in mind that about 80% of our dataset has not churned (or stayed a customer) and 20% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization\n",
    "\n",
    "This is a technique used to change the values of numeric columns in the dataset to a common scale, without distorting the differences in the ranges of values. This makes it easier for our model to understand the data and improve the accuracy of our predictions. Also, it is good practice to do this so that you don't have one variable dominating the other.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler will subtracting the mean of the data by the data point and then divided that value by the deviation. This will give us negative values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numeric_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "df_normalized = scaler.fit_transform(data[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert normalized array to DataFrame with column names\n",
    "df_normalized = pd.DataFrame(df_normalized, \n",
    "                           columns=numeric_columns, \n",
    "                           index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method of normalization is by using MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "df_normalized = scaler.fit_transform(data[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized_2 = pd.DataFrame(df_normalized, \n",
    "                           columns=numeric_columns, \n",
    "                           index=data.index)\n",
    "df_normalized_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MinMaxScaler did as expected which was making it so each data point was mapped to a value between 0 and 1 to represent where the value lies within the minimum and maximum value of the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** I will continue with the MinMaxScaler option, but could do some A/B testing with the other normalized set to see if we gain or lose performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized MinMaxScaler vs StandardScaler KNN Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add normalized data to our other indicators while also splitting out the training and test variables:\n",
    "extra_variables = ['CustomerId', 'Surname', 'Geography', 'Gender'] #keep in mind that customerid and surname should be unique\n",
    "model_x_extra = ['CustomerId', 'Gender', 'Geography']\n",
    "X_data = pd.concat([df_normalized_2, data[model_x_extra]], axis=1)\n",
    "y_data = data['Exited']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN, Logistic Regression, Decision Tree/random forests, XGBoost\n",
    "#start with KNN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=10)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the statistics from the KNN, we can see that the model is statstically signficant based on the accuracy being over the 60-70% mark. \n",
    "\n",
    "*Relearn precision, recall, f1-score.\n",
    "\n",
    "Our confusion matrix shows that we have 1522 true positives, 100 false positives, 351 false negatives, and 27 true negatives. Based on the TP rate we can see that it is correctly predicting positives 83% of the time which is very good. However, the true negatives was a bit lower than I would have expected. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 77% accuracy rating is pretty good, but what we can do is test multiple neighbor values to find the optimal amount of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test to see if the different normalization moethods affect our accuracy at all.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "df_normalized = scaler.fit_transform(data[numeric_columns])\n",
    "\n",
    "df_normalized = pd.DataFrame(df_normalized, \n",
    "                           columns=numeric_columns, \n",
    "                           index=data.index)\n",
    "\n",
    "extra_variables = ['CustomerId', 'Surname', 'Geography', 'Gender'] #keep in mind that customerid and surname should be unique\n",
    "model_x_extra = ['CustomerId', 'Gender', 'Geography']\n",
    "X_data = pd.concat([df_normalized, data[model_x_extra]], axis=1)\n",
    "y_data = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=10)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stick with the MinMaxScaler dataset:\n",
    "\n",
    "extra_variables = ['CustomerId', 'Surname', 'Geography', 'Gender'] #keep in mind that customerid and surname should be unique\n",
    "model_x_extra = ['CustomerId', 'Gender', 'Geography']\n",
    "X_data = pd.concat([df_normalized_2, data[model_x_extra]], axis=1)\n",
    "y_data = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accur = []\n",
    "\n",
    "for i in range(1, 50):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    knn_accur.append((i, accuracy_score(y_test, y_pred)))\n",
    "\n",
    "knn_df = pd.DataFrame(knn_accur, columns=['n_neighbors', 'accuracy'])\n",
    "\n",
    "plt.plot(knn_df.n_neighbors, knn_df.accuracy)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 5 neighbor accuracy values.\n",
    "knn_df_sorted = knn_df.sort_values(['accuracy'], ascending =False)\n",
    "print(knn_df_sorted.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best neighbor accuracy value example:\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=14)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphing the different clustrs\n",
    "\n",
    "#start here: https://plotly.com/python/knn-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_variables = ['CustomerId', 'Surname', 'Geography', 'Gender'] #keep in mind that customerid and surname should be unique\n",
    "model_x_extra = [ 'Gender', 'Geography']\n",
    "\n",
    "X_data = pd.concat([df_normalized_2, data[model_x_extra]], axis=1)\n",
    "y_data = data['Exited']\n",
    "\n",
    "print(X_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue with  https://www.datacamp.com/tutorial/understanding-logistic-regression-python\n",
    "\n",
    "#work on training the model and making sure to increase accuracy..\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=10)\n",
    "\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cnf_matrix, annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of our logistic regression seemed to have yeilded very similar results to our classification model. The models are great at predicting true churned customers, but there is a heavy favor towards false negatives meaning that the model predicted a non-churn when there actually was a churn. Thankfully this peice of the matrix isn't the strongest, however it is our second strongest, which means our model has poor accuracy when predicting true non-churn customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows the true positive rate against the false positive rate and being at 74% is on the weaker side, but not completely discountable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree/ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm).plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very simlar story to our other matrix tables. Strong true churns, but a second place variable of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~83% accuracy does show a significant statistic to use for production. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\n",
    "\n",
    "n = 100\n",
    "model = xgb.train(\n",
    "   params=params,\n",
    "   dtrain=dtrain_reg,\n",
    "   num_boost_round=n,\n",
    ")\n",
    "\n",
    "preds = model.predict(dtest_reg)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results seems to be very simlar with our other models, as in about 30% of the time, the model is off. According to standard statistics and data models in general 70% - 80% is proven to be significant, but usually not strong enough to go into production. Production level models should be in the 89-94% accuracy range. I believe with more data this dataset would provided a solid value for companies trying to preict churn based on banking finances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
